{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FinalYearProject_YOGA_IMPLEMENTATION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mOb2w7dNlaD"
      },
      "source": [
        "## FINAL YEAR PROJECT: YOGA POSE ESTIMATION AND FEEDBACK IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPFsdXEm0tJi"
      },
      "source": [
        "**Import the dataset from google drive**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_d2Xuy10mfK",
        "outputId": "ed1acae9-5d59-4204-df7c-99d3766389e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq_DE9_bNrGK"
      },
      "source": [
        "**Import the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhvToxBx3BBf"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg \n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEOeyQAUNu7J"
      },
      "source": [
        "**Path of training directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTlEFteu3NiN"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/College_amrita/FInalYearproject/Data/Cleansed_Data_Set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atcsDkZf7Bxh"
      },
      "source": [
        "y = enumerate(os.listdir(train_dir))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFC40cp-54jy"
      },
      "source": [
        "**After Loading the dataset, display some images from each asana**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUSvF5Qk5p5V"
      },
      "source": [
        "def plot_yoga_images(train_dir):\n",
        "  \n",
        "    plt.figure(figsize = (15,15))\n",
        "    for i, col in enumerate(os.listdir(train_dir)):\n",
        "        image = random.choice(os.listdir(train_dir + '/' + col))\n",
        "        image_path = train_dir + '/' + col + '/' + image\n",
        "        img = mpimg.imread(image_path)\n",
        "\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.title(col)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(False)\n",
        "        i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD0KWZpS6fTO"
      },
      "source": [
        "plot_yoga_images(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdjqIX5QFmmt"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyCfFIebhlL5"
      },
      "source": [
        "**Load the images from the dataset folder into a 2D array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJcFGlMIFZ_"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    count = 0\n",
        "    for filename in os.listdir(folder):\n",
        "        \n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            count += 1\n",
        "        if count > 5:\n",
        "          break\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u38tlC2sCRGK"
      },
      "source": [
        "dict = {0: 'downdog', 1: 'goddess', 2: 'plank', 3:  'warrior2'}\n",
        "\n",
        "\n",
        "def convert_dataset_to_2D_array(train_dir):\n",
        "  overall_images = []\n",
        "  k = os.listdir(train_dir) \n",
        "  k.sort()\n",
        "  for i, col in enumerate(k):\n",
        "\n",
        "    original_path = os.path.join(train_dir, col)    \n",
        "    images = load_images_from_folder(original_path)\n",
        "    overall_images.append(images)\n",
        "  return overall_images\n",
        "\n",
        "new = convert_dataset_to_2D_array(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aWUajiVMN3j"
      },
      "source": [
        "print(new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K46lPoXuOCbs"
      },
      "source": [
        "# Preprocessing Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMDGm8U9OF3D"
      },
      "source": [
        " **1. RESIZING IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqCl9-FbTBK0"
      },
      "source": [
        "DESIRED_HEIGHT = 480\n",
        "DESIRED_WIDTH = 480\n",
        "\n",
        "def resize_2D_array(overall_images):\n",
        "    new_arr_for_outerdirectory = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_for_subdirectory = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "\n",
        "\n",
        "        img = overall_images[i][j]\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        if h < w:\n",
        "          img = cv2.resize(img, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
        "          print(img.shape)\n",
        "          \n",
        "\n",
        "        else:\n",
        "          img = cv2.resize(img, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
        "          print(img.shape)\n",
        "          \n",
        "\n",
        "        #appending the image to a new array\n",
        "        new_array_for_subdirectory.append(img)\n",
        "      new_arr_for_outerdirectory.append(new_array_for_subdirectory)\n",
        "\n",
        "    return new_arr_for_outerdirectory\n",
        "\n",
        "newarray = resize_2D_array(new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgiWg_pjOL7S"
      },
      "source": [
        "**Function to display some images from each asana after every preprocessing step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-nN5YRtNTKj4"
      },
      "source": [
        "def print_some_images(overall_images):\n",
        "  for i in range(len(overall_images)):\n",
        "    for j in range(len(overall_images[i])):\n",
        "      cv2_imshow(overall_images[i][j])\n",
        "      k = 0\n",
        "\n",
        "print_some_images(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZOFgoeEOIYT"
      },
      "source": [
        " **2. BRIGHTNESS ADJUSTMENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AyWnlCweRSUK"
      },
      "source": [
        "#for brightness improvement\n",
        "\n",
        "def gammaCorrection(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        " \n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        " \n",
        "    return cv2.LUT(src, table)\n",
        "\n",
        "def isbright(image, dim=10):\n",
        "    # Resize image to 10x10\n",
        "    image = cv2.resize(image, (dim, dim))\n",
        "    # Convert color space to LAB format and extract L channel\n",
        "    L, A, B = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2LAB))\n",
        "    # Normalize L channel by dividing all pixel values with maximum pixel value\n",
        "    L = L/np.max(L)\n",
        "    # Return True if mean is greater than thresh else False\n",
        "    return np.mean(L)\n",
        "\n",
        "def changeBrightness(image):\n",
        "\n",
        "  if (isbright(image) < 0.5):\n",
        "    gammaImg = gammaCorrection(image, 1)\n",
        "  elif (isbright(image) > 0.85):\n",
        "    gammaImg = gammaCorrection(image, 0.75)\n",
        "  else:\n",
        "    gammaImg = image\n",
        "  return gammaImg\n",
        "\n",
        "\n",
        "def improve_brightness(overall_images):\n",
        "    new_arr = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_1 = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "\n",
        "        img = changeBrightness(overall_images[i][j])\n",
        "        #appending the image to a new array\n",
        "        new_array_1.append(img)\n",
        "      new_arr.append(new_array_1)\n",
        "    return new_arr\n",
        "    \n",
        "newarray = improve_brightness(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IBI5Y7oGVqrH"
      },
      "source": [
        "print_some_images(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC34wQpPOPuJ"
      },
      "source": [
        " **3. CONTRAST ADJUSTMENT USING HISTOGRAM EQUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Y0gztVl1Yyv"
      },
      "source": [
        "import numpy as np\n",
        "from skimage.exposure import is_low_contrast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KMS_xqk-2wbS"
      },
      "source": [
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    \n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "    \n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "21W8aJDF_2ac"
      },
      "source": [
        "def improve_contrast(overall_images):\n",
        "    new_arr = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_1 = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "        \n",
        "        img = overall_images[i][j]\n",
        "        if(is_low_contrast(img, fraction_threshold=0.05, lower_percentile=1, upper_percentile=99, method='linear')):\n",
        "          img = histogram_equalization(img)\n",
        "\n",
        "        #appending the image to a new array\n",
        "        new_array_1.append(img)\n",
        "      new_arr.append(new_array_1)\n",
        "    return new_arr\n",
        "\n",
        "\n",
        "newarray = improve_contrast(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KGkNYEFwNgdU"
      },
      "source": [
        "print_some_images(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM_N4lcKOgbc"
      },
      "source": [
        " **4. SHARPENING IMAGES USING LAPLACIAN OPERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I4r_o9ibW33G"
      },
      "source": [
        "def sharpenimage(image):\n",
        "  laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
        "  if laplacian_var < 100:\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                      [-1, 5,-1],\n",
        "                      [0, -1, 0]])\n",
        "\n",
        "    sharpened_img = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
        "  else:\n",
        "    sharpened_img = image\n",
        "  return sharpened_img\n",
        "\n",
        "def improve_sharpening(overall_images):\n",
        "    new_arr = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_1 = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "        img = sharpenimage(overall_images[i][j])\n",
        "        #appending the image to a new array\n",
        "        new_array_1.append(img)\n",
        "      new_arr.append(new_array_1)\n",
        "\n",
        "    return new_arr\n",
        "# now new array will contain the sharpened  images\n",
        "newarray=improve_sharpening(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MbFatbNrXVtW"
      },
      "source": [
        "print_some_images(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpOh8Ymvbmzc"
      },
      "source": [
        "# MEDIAPIPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bBzg5p0wcjv9"
      },
      "source": [
        "image = cv2.imread('/content/sample_data/yoga_test.png',1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWg_1cWTb3cB"
      },
      "source": [
        "**Installing mediapipe library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SelHQ4IbbxiH",
        "outputId": "d5e82e88-2004-4c50-9612-1c1a05391f28"
      },
      "source": [
        "pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.37.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ogDvevPOzCk"
      },
      "source": [
        "**Import mediapipe library for background segmentation, pose landmarks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3gH1GsWObvTk"
      },
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "import numpy as np\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzgVOzBZ65yu"
      },
      "source": [
        "**1. BACKGROUND SEGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9aXgM4E67Rq"
      },
      "source": [
        "# Run MediaPipe Pose with `enable_segmentation=True` to get pose segmentation.\n",
        "\n",
        "\n",
        "def md_enable_segmentation(image):\n",
        "  with mp_pose.Pose( static_image_mode=True, min_detection_confidence=0.50,model_complexity=2, enable_segmentation=True) as pose:\n",
        "    \n",
        "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    \n",
        "      # Draw pose segmentation.\n",
        "    annotated_image = image.copy()\n",
        "    red_img = np.zeros_like(annotated_image, dtype=np.uint8)\n",
        "    red_img[:, :] = (255,255,255)\n",
        "    segm_2class = 0.2 + 0.8 * results.segmentation_mask\n",
        "    segm_2class = np.repeat(segm_2class[..., np.newaxis], 3, axis=2)\n",
        "    annotated_image = annotated_image * segm_2class + red_img * (1 - segm_2class)\n",
        "    img_some = annotated_image\n",
        "    annotated_image= cv2.normalize(annotated_image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "\n",
        "    # cv2_imshow(annotated_image)\n",
        "  return annotated_image\n",
        "\n",
        "\n",
        "\n",
        "def body_segmentation(overall_images):\n",
        "    new_arr = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_1 = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "        img = md_enable_segmentation(overall_images[i][j])\n",
        "        #appending the image to a new array\n",
        "        new_array_1.append(img)\n",
        "      new_arr.append(new_array_1)\n",
        "\n",
        "    return new_arr\n",
        "newarray = body_segmentation(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2b5PvUe7jHT"
      },
      "source": [
        "print_some_images(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GKceP0ocEmK"
      },
      "source": [
        "**2. DETECTING POSE LANDMARKS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaDc0DLKcH-n"
      },
      "source": [
        "def detectPose(image, pose, display=True):\n",
        "\n",
        "    \n",
        "    # Create a copy of the input image.\n",
        "    output_image = image.copy()\n",
        "    \n",
        "    # Convert the image from BGR into RGB format.\n",
        "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Perform the Pose Detection.\n",
        "    results = pose.process(imageRGB)\n",
        "    \n",
        "    # Retrieve the height and width of the input image.\n",
        "    height, width, _ = image.shape\n",
        "    \n",
        "    # Initialize a list to store the detected landmarks.\n",
        "    landmarks = []\n",
        "    \n",
        "    # Check if any landmarks are detected.\n",
        "    if results.pose_landmarks:\n",
        "    \n",
        "        # Draw Pose landmarks on the output image.\n",
        "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
        "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
        "        \n",
        "        # Iterate over the detected landmarks.\n",
        "        for landmark in results.pose_landmarks.landmark:\n",
        "            \n",
        "            # Append the landmark into the list.\n",
        "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
        "                                  (landmark.z * width)))\n",
        "    \n",
        "    # Check if the original input image and the resultant image are specified to be displayed.\n",
        "    if display:\n",
        "    \n",
        "        # Display the original input image and the resultant image.\n",
        "        plt.figure(figsize=[22,22])\n",
        "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
        "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
        "        \n",
        "        # Also Plot the Pose landmarks in 3D.\n",
        "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "        \n",
        "    # Otherwise\n",
        "    else:\n",
        "        \n",
        "        # Return the output image and the found landmarks.\n",
        "        return output_image, landmarks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siVMXP-bctjM"
      },
      "source": [
        "# pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
        "\n",
        "# detectPose(image, pose, display=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atHK0AA9b7Do"
      },
      "source": [
        "**Code to calculate angles given 3 points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qldXRCOQbqQo"
      },
      "source": [
        "def calculateAngle(landmark1, landmark2, landmark3):\n",
        "\n",
        " \n",
        "    x1, y1, _ = landmark1\n",
        "    x2, y2, _ = landmark2\n",
        "    x3, y3, _ = landmark3\n",
        " \n",
        "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
        "    \n",
        "    # Check if the angle is less than zero. \n",
        "    if angle< 0:\n",
        " \n",
        "        # Add 360 to the found angle.\n",
        "        angle += 360\n",
        "    \n",
        "    return angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSo2f99jcBR2"
      },
      "source": [
        "angle = calculateAngle((558, 326, 0), (642, 333, 0), (718, 321, 0))\n",
        "print(angle , \"angle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRWQ0SnhcPp8"
      },
      "source": [
        "**Calculate body angles from the different joints:**\n",
        "\n",
        "**1. LEFT AND RIGHT WRIST**\n",
        "\n",
        "**2. LEFT AND RIGHT ELBOW**\n",
        "\n",
        "**3. LEFT AND RIGHT SHOULDER**\n",
        "\n",
        "**4. LEFT AND RIGHT KNEE**\n",
        "\n",
        "**5. LEFT AND RIGHT ANKLE**\n",
        "\n",
        "**6. LEFT AND RIGHT HIPS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqa0lOmfcR2q"
      },
      "source": [
        "def classifyPose_to_csv(landmarks, output_image, display=False):\n",
        "    \n",
        "    angles = []\n",
        "    \n",
        "    # Initialize the label of the pose. It is not known at this stage.\n",
        "    label = 'Unknown Pose'\n",
        "\n",
        "    # Specify the color (Red) with which the label will be written on the image.\n",
        "    color = (0, 0, 255)\n",
        "    \n",
        "    # Calculate the required angles.\n",
        "    #----------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # Get the angle between the left elbow, wrist and left index points. \n",
        "    left_wrist_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value])\n",
        "    angles.append(left_wrist_angle)\n",
        "    # Get the angle between the right elbow, wrist and left index points. \n",
        "    right_wrist_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
        "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
        "                                       landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value])   \n",
        "    angles.append(right_wrist_angle)\n",
        "\n",
        "    \n",
        "    # Get the angle between the left shoulder, elbow and wrist points. \n",
        "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
        "    angles.append(left_elbow_angle)\n",
        "    # Get the angle between the right shoulder, elbow and wrist points. \n",
        "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
        "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
        "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n",
        "    angles.append(right_elbow_angle)\n",
        "    # Get the angle between the left elbow, shoulder and hip points. \n",
        "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
        "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
        "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
        "    angles.append(left_shoulder_angle)\n",
        "\n",
        "    # Get the angle between the right hip, shoulder and elbow points. \n",
        "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
        "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
        "    angles.append(right_shoulder_angle)\n",
        "\n",
        "    # Get the angle between the left hip, knee and ankle points. \n",
        "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
        "    angles.append(left_knee_angle)\n",
        "\n",
        "    # Get the angle between the right hip, knee and ankle points \n",
        "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
        "    angles.append(right_knee_angle)\n",
        "\n",
        "        # Get the angle between the left hip, ankle and LEFT_FOOT_INDEX points. \n",
        "    left_ankle_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value])\n",
        "    angles.append(left_ankle_angle)\n",
        "\n",
        "    # Get the angle between the right hip, ankle and RIGHT_FOOT_INDEX points \n",
        "    right_ankle_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value])\n",
        "    angles.append(right_ankle_angle)\n",
        "\n",
        "    # Get the angle between the left knee, hip and right hip points. \n",
        "    left_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
        "    angles.append(left_hip_angle)\n",
        "\n",
        "    # Get the angle between the left hip, right hip and right kneee points \n",
        "    right_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
        "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
        "    angles.append(right_hip_angle)\n",
        "\n",
        "    # print(left_elbow_angle, \" left_elbow_angle \", right_elbow_angle , \" right_elbow_angle \",left_shoulder_angle,\" left_shoulder_angle \",right_shoulder_angle,\" right_shoulder_angle \",left_knee_angle,\" left_knee_angle \", right_knee_angle,\" right_knee_angle \" , left_ankle_angle, \" left_ankle_angle \",right_ankle_angle,\" right_ankle_angle \")\n",
        "    # print(angles)\n",
        "    return angles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkQe8R3mcOyc"
      },
      "source": [
        "# image = image\n",
        "# output_image, landmarks = detectPose(image, pose, display=False)\n",
        "# if landmarks:\n",
        "#     print(classifyPose_to_csv(landmarks, output_image, display=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOcLzYxHQC2r"
      },
      "source": [
        "**Calculate body angles for every asana**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5iw1hv6bq2q"
      },
      "source": [
        "def Calc_angles(overall_images):\n",
        "    angles_list = []\n",
        "    new_arr = []\n",
        "    for i in range(len(overall_images)):\n",
        "      col = dict[i]\n",
        "      new_array_1 = []\n",
        "      for j in range(len(overall_images[i])):\n",
        "        \n",
        "        img = overall_images[i][j]\n",
        "        output_image, landmarks = detectPose(img, pose, display=False)\n",
        "        if landmarks:\n",
        "            k = classifyPose_to_csv(landmarks, output_image, display=True)\n",
        "            k.insert(0,i)\n",
        "            angles_list.append(k)\n",
        "        else:\n",
        "          continue\n",
        "        #appending the image to a new array\n",
        "        \n",
        "      # new_arr.append(new_array_1)\n",
        "    return angles_list\n",
        "\n",
        "\n",
        "angles_array = Calc_angles(newarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRpBkxRhfe2B"
      },
      "source": [
        "**The First coulmn denotes {0: 'downdog', 1: 'goddess', 2: 'plank', 3: 'warrior2'}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-6kKajFdiUA"
      },
      "source": [
        "j = 0\n",
        "for i in angles_array:\n",
        "  j += 1\n",
        "  print(i)\n",
        "  if(j>17):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw7fUchceyUe"
      },
      "source": [
        "len(angles_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3dnU1OEBo4K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GusIuxH2QU1j"
      },
      "source": [
        "**Import necessary libraries**\n",
        "\n",
        "**Convert the 2D angle array into a dataframe and add column headers for every angle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg-rjddLmQS-"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(angles_array)\n",
        "df.columns =['Pose',\"left_wrist_angle\" , \"right_wrist_angle\" , \"left_elbow_angle\" , \"right_elbow_angle\" , \"left_shoulder_angle\" , \"right_shoulder_angle\",\"left_knee_angle\",\"right_knee_angle\",\"left_ankle_angle\",\"right_ankle_angle\",\"left_hip_angle\",\"right_hip_angle\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwlH78mqicfK"
      },
      "source": [
        "df.to_csv('/content/sample_data/yoga_index.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lro73w7BTAn"
      },
      "source": [
        "df2=df.replace({\"Pose\": dict})\n",
        "print(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9F1aDDCQN82"
      },
      "source": [
        "**Convert the body angles dataframe to a csv file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr9RxAiLC-Ak"
      },
      "source": [
        "df2.to_csv('/content/sample_data/yoga_nameindex.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TcXpuN-DagT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}